{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "name": "Rijul_Vohra_hw05_snorkel.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsYZtjrqxKGP",
        "colab_type": "text"
      },
      "source": [
        "# Using Snorkel to Extract Education of Actresses and Actors\n",
        "\n",
        "<sub>Content of this notebook was prepared by Basel Shbita (shbita@usc.edu) as part of the class <u>CSCI 563/INF 558: Building Knowledge Graphs</u> during Spring 2020 at University of Southern California (USC).</sub>\n",
        "\n",
        "**Notes**: \n",
        "- You are supposed to write your code or modify our code in any cell starting with `# ** STUDENT CODE`.\n",
        "- Much content of this notebook was borrowed from Snorkel Introduction Tutorial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9J26ZuLcxKGV",
        "colab_type": "text"
      },
      "source": [
        "State-of-the-art extraction techniques require massive labeled training set but it is costly to obtain. To overcome this problem, Snorkel helps rapidly create training sets using the new data programming paradigm. To start, developers focus on writing a set of labeling functions, which are just scripts that programmatically label data. The resulting labels are noisy, but Snorkel uses a generative model to learn how to use those labeling functions to label more data. The new labeled data now can be used to train high-quality end models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YfIWsfN6xKGf",
        "colab_type": "text"
      },
      "source": [
        "**In summary, in this task, you will first manually label 99 documents and use these labeled data as a development set to create your own labeling functions. Then, you will train a generative model to label 1025 documents in training set. Finally, you will train a discriminative model (Bi-LSTM) to produce your final extraction model!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlXtFBTQxKGj",
        "colab_type": "text"
      },
      "source": [
        "## Prepare environment\n",
        "\n",
        "Lets install the packages we will use"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "AXzUXIhoxKHN",
        "colab_type": "code",
        "colab": {},
        "outputId": "67b079fe-05c4-4129-b7c4-131de2741eda"
      },
      "source": [
        "!pip install SPARQLWrapper"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting SPARQLWrapper\n",
            "  Downloading SPARQLWrapper-1.8.5-py3-none-any.whl (26 kB)\n",
            "Collecting rdflib>=4.0\n",
            "  Downloading rdflib-4.2.2-py3-none-any.whl (344 kB)\n",
            "\u001b[K     |████████████████████████████████| 344 kB 7.2 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting isodate\n",
            "  Downloading isodate-0.6.0-py2.py3-none-any.whl (45 kB)\n",
            "\u001b[K     |████████████████████████████████| 45 kB 2.4 MB/s  eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: pyparsing in /opt/conda/lib/python3.6/site-packages (from rdflib>=4.0->SPARQLWrapper) (2.4.6)\n",
            "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from isodate->rdflib>=4.0->SPARQLWrapper) (1.14.0)\n",
            "Installing collected packages: isodate, rdflib, SPARQLWrapper\n",
            "Successfully installed SPARQLWrapper-1.8.5 isodate-0.6.0 rdflib-4.2.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "HoY7TX1-xKHj",
        "colab_type": "code",
        "colab": {},
        "outputId": "8e6263ca-9268-4123-cd12-4a442f3236f2"
      },
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scipy==1.2.1\n",
            "  Downloading scipy-1.2.1-cp36-cp36m-manylinux1_x86_64.whl (24.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 24.8 MB 5.1 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 2)) (1.18.1)\n",
            "Requirement already satisfied: spacy in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 3)) (2.2.3)\n",
            "Requirement already satisfied: pandas in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 4)) (0.25.3)\n",
            "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 5)) (3.0.3)\n",
            "Collecting ujson\n",
            "  Downloading ujson-2.0.1.tar.gz (7.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1 MB 23.3 MB/s eta 0:00:01\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 7)) (2.22.0)\n",
            "Requirement already satisfied: bs4 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 8)) (0.0.1)\n",
            "Requirement already satisfied: future in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 9)) (0.18.2)\n",
            "Requirement already satisfied: lxml in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 10)) (4.5.0)\n",
            "Requirement already satisfied: numba in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 11)) (0.48.0)\n",
            "Collecting numbskull\n",
            "  Downloading numbskull-0.1.1-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: sqlalchemy in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 13)) (1.3.13)\n",
            "Collecting treedlib\n",
            "  Downloading treedlib-0.1.2-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: torch in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 15)) (1.4.0)\n",
            "Requirement already satisfied: nltk in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 16)) (3.2.4)\n",
            "Requirement already satisfied: thinc<7.4.0,>=7.3.0 in /opt/conda/lib/python3.6/site-packages (from spacy->-r requirements.txt (line 3)) (7.3.1)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /opt/conda/lib/python3.6/site-packages (from spacy->-r requirements.txt (line 3)) (0.4.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=0.1.0 in /opt/conda/lib/python3.6/site-packages (from spacy->-r requirements.txt (line 3)) (1.0.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from spacy->-r requirements.txt (line 3)) (3.0.2)\n",
            "Requirement already satisfied: setuptools in /opt/conda/lib/python3.6/site-packages (from spacy->-r requirements.txt (line 3)) (45.2.0.post20200210)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /opt/conda/lib/python3.6/site-packages (from spacy->-r requirements.txt (line 3)) (0.6.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /opt/conda/lib/python3.6/site-packages (from spacy->-r requirements.txt (line 3)) (1.0.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /opt/conda/lib/python3.6/site-packages (from spacy->-r requirements.txt (line 3)) (0.9.6)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.6/site-packages (from spacy->-r requirements.txt (line 3)) (1.0.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from spacy->-r requirements.txt (line 3)) (2.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /opt/conda/lib/python3.6/site-packages (from pandas->-r requirements.txt (line 4)) (2.8.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.6/site-packages (from pandas->-r requirements.txt (line 4)) (2019.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.6/site-packages (from matplotlib->-r requirements.txt (line 5)) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib->-r requirements.txt (line 5)) (1.1.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib->-r requirements.txt (line 5)) (2.4.6)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->-r requirements.txt (line 7)) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->-r requirements.txt (line 7)) (2019.11.28)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->-r requirements.txt (line 7)) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->-r requirements.txt (line 7)) (3.0.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.6/site-packages (from bs4->-r requirements.txt (line 8)) (4.8.2)\n",
            "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /opt/conda/lib/python3.6/site-packages (from numba->-r requirements.txt (line 11)) (0.31.0)\n",
            "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from nltk->-r requirements.txt (line 16)) (1.14.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /opt/conda/lib/python3.6/site-packages (from thinc<7.4.0,>=7.3.0->spacy->-r requirements.txt (line 3)) (4.42.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /opt/conda/lib/python3.6/site-packages (from catalogue<1.1.0,>=0.0.7->spacy->-r requirements.txt (line 3)) (1.5.0)\n",
            "Requirement already satisfied: soupsieve>=1.2 in /opt/conda/lib/python3.6/site-packages (from beautifulsoup4->bs4->-r requirements.txt (line 8)) (1.9.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy->-r requirements.txt (line 3)) (2.2.0)\n",
            "Building wheels for collected packages: ujson\n",
            "  Building wheel for ujson (PEP 517) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for ujson: filename=ujson-2.0.1-cp36-cp36m-linux_x86_64.whl size=180579 sha256=003ebd37c51c12f12f2aa9bb2375ea7bc2b576ca06923e505ed230e5789c668c\n",
            "  Stored in directory: /root/.cache/pip/wheels/14/73/f1/7fcd5554ae4312f31645e9b787fe496406e32b7df9972b7180\n",
            "Successfully built ujson\n",
            "\u001b[31mERROR: tpot 0.11.1 has requirement scipy>=1.3.1, but you'll have scipy 1.2.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.1.0 has requirement scipy==1.4.1; python_version >= \"3\", but you'll have scipy 1.2.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: pandas-profiling 2.5.0 has requirement scipy>=1.4.1, but you'll have scipy 1.2.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: kmeans-smote 0.1.2 has requirement imbalanced-learn<0.5,>=0.4.0, but you'll have imbalanced-learn 0.6.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: kmeans-smote 0.1.2 has requirement numpy<1.16,>=1.13, but you'll have numpy 1.18.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: kmeans-smote 0.1.2 has requirement scikit-learn<0.21,>=0.19.0, but you'll have scikit-learn 0.22.2.post1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: hypertools 0.6.2 has requirement scikit-learn<0.22,>=0.19.1, but you'll have scikit-learn 0.22.2.post1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: hyperopt 0.2.3 has requirement networkx==2.2, but you'll have networkx 2.4 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: giddy 2.3.0 has requirement scipy>=1.3.0, but you'll have scipy 1.2.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: allennlp 0.9.0 has requirement spacy<2.2,>=2.1.0, but you'll have spacy 2.2.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: scipy, ujson, numbskull, treedlib\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "Successfully installed numbskull-0.1.1 scipy-1.2.1 treedlib-0.1.2 ujson-2.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzfGyr92xKH0",
        "colab_type": "text"
      },
      "source": [
        "We will work with Snorkel version 0.7 (Beta), we can retrieve it by running the following commands:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "PmYRzAd_xKH6",
        "colab_type": "code",
        "colab": {},
        "outputId": "0064f66c-af6f-4c1b-d41b-3f76a51c496a"
      },
      "source": [
        "\n",
        "!curl -L \"https://github.com/snorkel-team/snorkel/archive/v0.7.0-beta.tar.gz\" -o snorkel_v0_7_0.tar.gz"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   133  100   133    0     0    610      0 --:--:-- --:--:-- --:--:--   610\n",
            "100 60.2M    0 60.2M    0     0  9715k      0 --:--:--  0:00:06 --:--:-- 11.6M\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIlhu7uDxKIH",
        "colab_type": "text"
      },
      "source": [
        "Now let's uncompress the package and install Snorkel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "aTmt4UGIxKIO",
        "colab_type": "code",
        "colab": {},
        "outputId": "bcd8a20c-8848-489d-feac-1c08e8f9ed1c"
      },
      "source": [
        "!tar -xvzf snorkel_v0_7_0.tar.gz"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "snorkel-0.7.0-beta/\n",
            "snorkel-0.7.0-beta/.gitattributes\n",
            "snorkel-0.7.0-beta/.gitignore\n",
            "snorkel-0.7.0-beta/.travis.yml\n",
            "snorkel-0.7.0-beta/CODE_OF_CONDUCT.md\n",
            "snorkel-0.7.0-beta/LICENSE\n",
            "snorkel-0.7.0-beta/MANIFEST.in\n",
            "snorkel-0.7.0-beta/README.md\n",
            "snorkel-0.7.0-beta/docs/\n",
            "snorkel-0.7.0-beta/docs/Makefile\n",
            "snorkel-0.7.0-beta/docs/README.md\n",
            "snorkel-0.7.0-beta/docs/annotations.txt\n",
            "snorkel-0.7.0-beta/docs/candidates.txt\n",
            "snorkel-0.7.0-beta/docs/conf.py\n",
            "snorkel-0.7.0-beta/docs/contexts.txt\n",
            "snorkel-0.7.0-beta/docs/etc.txt\n",
            "snorkel-0.7.0-beta/docs/images/\n",
            "snorkel-0.7.0-beta/docs/images/logo.png\n",
            "snorkel-0.7.0-beta/docs/index.txt\n",
            "snorkel-0.7.0-beta/docs/learning.txt\n",
            "snorkel-0.7.0-beta/environment.yml\n",
            "snorkel-0.7.0-beta/figs/\n",
            "snorkel-0.7.0-beta/figs/ONR.jpg\n",
            "snorkel-0.7.0-beta/figs/darpa.JPG\n",
            "snorkel-0.7.0-beta/figs/logo_01.png\n",
            "snorkel-0.7.0-beta/figs/mobilize_logo.png\n",
            "snorkel-0.7.0-beta/figs/moore_logo.png\n",
            "snorkel-0.7.0-beta/figs/nih_logo.png\n",
            "snorkel-0.7.0-beta/figs/user_logos.png\n",
            "snorkel-0.7.0-beta/setup.py\n",
            "snorkel-0.7.0-beta/snorkel/\n",
            "snorkel-0.7.0-beta/snorkel/__init__.py\n",
            "snorkel-0.7.0-beta/snorkel/annotations.py\n",
            "snorkel-0.7.0-beta/snorkel/candidates.py\n",
            "snorkel-0.7.0-beta/snorkel/contrib/\n",
            "snorkel-0.7.0-beta/snorkel/contrib/__init__.py\n",
            "snorkel-0.7.0-beta/snorkel/contrib/brat/\n",
            "snorkel-0.7.0-beta/snorkel/contrib/brat/__init__.py\n",
            "snorkel-0.7.0-beta/snorkel/contrib/brat/brat.py\n",
            "snorkel-0.7.0-beta/snorkel/contrib/brat/install.sh\n",
            "snorkel-0.7.0-beta/snorkel/contrib/brat/templates/\n",
            "snorkel-0.7.0-beta/snorkel/contrib/brat/templates/annotation.config.tmpl\n",
            "snorkel-0.7.0-beta/snorkel/contrib/brat/templates/tools.conf\n",
            "snorkel-0.7.0-beta/snorkel/contrib/brat/tools.py\n",
            "snorkel-0.7.0-beta/snorkel/contrib/brat/utils.py\n",
            "snorkel-0.7.0-beta/snorkel/contrib/disc_learning/\n",
            "snorkel-0.7.0-beta/snorkel/contrib/disc_learning/__init__.py\n",
            "snorkel-0.7.0-beta/snorkel/contrib/disc_learning/fmc/\n",
            "snorkel-0.7.0-beta/snorkel/contrib/disc_learning/fmc/fastmulticontext.py\n",
            "snorkel-0.7.0-beta/snorkel/contrib/embedding/\n",
            "snorkel-0.7.0-beta/snorkel/contrib/embedding/__init__.py\n",
            "snorkel-0.7.0-beta/snorkel/contrib/embedding/lsa_embedding.py\n",
            "snorkel-0.7.0-beta/snorkel/contrib/embedding/sppmi_svd_embedding.py\n",
            "snorkel-0.7.0-beta/snorkel/contrib/embedding/utils.py\n",
            "snorkel-0.7.0-beta/snorkel/contrib/gen_learning/\n",
            "snorkel-0.7.0-beta/snorkel/contrib/gen_learning/featurizedmodel/\n",
            "snorkel-0.7.0-beta/snorkel/contrib/gen_learning/featurizedmodel/__init__.py\n",
            "snorkel-0.7.0-beta/snorkel/contrib/gen_learning/featurizedmodel/gen_learning.py\n",
            "snorkel-0.7.0-beta/snorkel/contrib/models/\n",
            "snorkel-0.7.0-beta/snorkel/contrib/models/__init__.py\n",
            "snorkel-0.7.0-beta/snorkel/contrib/models/text.py\n",
            "snorkel-0.7.0-beta/snorkel/contrib/parser/\n",
            "snorkel-0.7.0-beta/snorkel/contrib/parser/spacy.py\n",
            "snorkel-0.7.0-beta/snorkel/contrib/snark/\n",
            "snorkel-0.7.0-beta/snorkel/contrib/snark/__init__.py\n",
            "snorkel-0.7.0-beta/snorkel/contrib/snark/annotations.py\n",
            "snorkel-0.7.0-beta/snorkel/contrib/snark/models/\n",
            "snorkel-0.7.0-beta/snorkel/contrib/snark/models/__init__.py\n",
            "snorkel-0.7.0-beta/snorkel/contrib/snark/models/candidate.py\n",
            "snorkel-0.7.0-beta/snorkel/contrib/snark/models/context.py\n",
            "snorkel-0.7.0-beta/snorkel/contrib/snark/parser.py\n",
            "snorkel-0.7.0-beta/snorkel/db_helpers.py\n",
            "snorkel-0.7.0-beta/snorkel/features/\n",
            "snorkel-0.7.0-beta/snorkel/features/__init__.py\n",
            "snorkel-0.7.0-beta/snorkel/features/context_features.py\n",
            "snorkel-0.7.0-beta/snorkel/features/entity_features.py\n",
            "snorkel-0.7.0-beta/snorkel/features/generic_features.py\n",
            "snorkel-0.7.0-beta/snorkel/features/relative_features.py\n",
            "snorkel-0.7.0-beta/snorkel/learning/\n",
            "snorkel-0.7.0-beta/snorkel/learning/__init__.py\n",
            "snorkel-0.7.0-beta/snorkel/learning/classifier.py\n",
            "snorkel-0.7.0-beta/snorkel/learning/gen_learning.py\n",
            "snorkel-0.7.0-beta/snorkel/learning/pytorch/\n",
            "snorkel-0.7.0-beta/snorkel/learning/pytorch/__init__.py\n",
            "snorkel-0.7.0-beta/snorkel/learning/pytorch/logistic_regression.py\n",
            "snorkel-0.7.0-beta/snorkel/learning/pytorch/noise_aware_model.py\n",
            "snorkel-0.7.0-beta/snorkel/learning/pytorch/rnn/\n",
            "snorkel-0.7.0-beta/snorkel/learning/pytorch/rnn/__init__.py\n",
            "snorkel-0.7.0-beta/snorkel/learning/pytorch/rnn/lstm.py\n",
            "snorkel-0.7.0-beta/snorkel/learning/pytorch/rnn/rnn_base.py\n",
            "snorkel-0.7.0-beta/snorkel/learning/pytorch/rnn/utils.py\n",
            "snorkel-0.7.0-beta/snorkel/learning/structure/\n",
            "snorkel-0.7.0-beta/snorkel/learning/structure/__init__.py\n",
            "snorkel-0.7.0-beta/snorkel/learning/structure/constants.py\n",
            "snorkel-0.7.0-beta/snorkel/learning/structure/gen_learning.py\n",
            "snorkel-0.7.0-beta/snorkel/learning/structure/synthetic.py\n",
            "snorkel-0.7.0-beta/snorkel/learning/structure/utils.py\n",
            "snorkel-0.7.0-beta/snorkel/learning/tensorflow/\n",
            "snorkel-0.7.0-beta/snorkel/learning/tensorflow/__init__.py\n",
            "snorkel-0.7.0-beta/snorkel/learning/tensorflow/logistic_regression.py\n",
            "snorkel-0.7.0-beta/snorkel/learning/tensorflow/noise_aware_model.py\n",
            "snorkel-0.7.0-beta/snorkel/learning/tensorflow/rnn/\n",
            "snorkel-0.7.0-beta/snorkel/learning/tensorflow/rnn/__init__.py\n",
            "snorkel-0.7.0-beta/snorkel/learning/tensorflow/rnn/re_rnn.py\n",
            "snorkel-0.7.0-beta/snorkel/learning/tensorflow/rnn/rnn_base.py\n",
            "snorkel-0.7.0-beta/snorkel/learning/tensorflow/rnn/tag_rnn.py\n",
            "snorkel-0.7.0-beta/snorkel/learning/tensorflow/rnn/text_rnn.py\n",
            "snorkel-0.7.0-beta/snorkel/learning/tensorflow/rnn/utils.py\n",
            "snorkel-0.7.0-beta/snorkel/learning/utils.py\n",
            "snorkel-0.7.0-beta/snorkel/lf_helpers.py\n",
            "snorkel-0.7.0-beta/snorkel/matcher_utils.py\n",
            "snorkel-0.7.0-beta/snorkel/matchers.py\n",
            "snorkel-0.7.0-beta/snorkel/models/\n",
            "snorkel-0.7.0-beta/snorkel/models/__init__.py\n",
            "snorkel-0.7.0-beta/snorkel/models/annotation.py\n",
            "snorkel-0.7.0-beta/snorkel/models/candidate.py\n",
            "snorkel-0.7.0-beta/snorkel/models/context.py\n",
            "snorkel-0.7.0-beta/snorkel/models/meta.py\n",
            "snorkel-0.7.0-beta/snorkel/models/views.py\n",
            "snorkel-0.7.0-beta/snorkel/parser/\n",
            "snorkel-0.7.0-beta/snorkel/parser/__init__.py\n",
            "snorkel-0.7.0-beta/snorkel/parser/corenlp.py\n",
            "snorkel-0.7.0-beta/snorkel/parser/corpus_parser.py\n",
            "snorkel-0.7.0-beta/snorkel/parser/doc_preprocessors.py\n",
            "snorkel-0.7.0-beta/snorkel/parser/parser.py\n",
            "snorkel-0.7.0-beta/snorkel/parser/rule_parser.py\n",
            "snorkel-0.7.0-beta/snorkel/parser/spacy_parser.py\n",
            "snorkel-0.7.0-beta/snorkel/udf.py\n",
            "snorkel-0.7.0-beta/snorkel/utils.py\n",
            "snorkel-0.7.0-beta/snorkel/viewer/\n",
            "snorkel-0.7.0-beta/snorkel/viewer/__init__.py\n",
            "snorkel-0.7.0-beta/snorkel/viewer/viewer.html\n",
            "snorkel-0.7.0-beta/snorkel/viewer/viewer.js\n",
            "snorkel-0.7.0-beta/snorkel/vis/\n",
            "snorkel-0.7.0-beta/snorkel/vis/__init__.py\n",
            "snorkel-0.7.0-beta/snorkel/vis/tree-chart.html\n",
            "snorkel-0.7.0-beta/snorkel/vis/tree-chart.js\n",
            "snorkel-0.7.0-beta/snorkel/vis/tree_structs.py\n",
            "snorkel-0.7.0-beta/test/\n",
            "snorkel-0.7.0-beta/test/learning/\n",
            "snorkel-0.7.0-beta/test/learning/pytorch/\n",
            "snorkel-0.7.0-beta/test/learning/pytorch/pytorch_test_base.py\n",
            "snorkel-0.7.0-beta/test/learning/pytorch/spouses.db\n",
            "snorkel-0.7.0-beta/test/learning/pytorch/test_determinism.py\n",
            "snorkel-0.7.0-beta/test/learning/pytorch/test_logistic_regression.py\n",
            "snorkel-0.7.0-beta/test/learning/pytorch/test_lstm.py\n",
            "snorkel-0.7.0-beta/test/learning/pytorch/test_model_reloading.py\n",
            "snorkel-0.7.0-beta/test/learning/tensorflow/\n",
            "snorkel-0.7.0-beta/test/learning/tensorflow/crowdsourcing.db\n",
            "snorkel-0.7.0-beta/test/learning/tensorflow/crowdsourcing_test_labels.npy\n",
            "snorkel-0.7.0-beta/test/learning/tensorflow/crowdsourcing_train_labels.npy\n",
            "snorkel-0.7.0-beta/test/learning/tensorflow/test_TF_notebook.ipynb\n",
            "snorkel-0.7.0-beta/test/learning/tensorflow/test_parallel_grid_search.ipynb\n",
            "snorkel-0.7.0-beta/test/learning/test_categorical.py\n",
            "snorkel-0.7.0-beta/test/learning/test_gen_learning.py\n",
            "snorkel-0.7.0-beta/test/learning/test_supervised.py\n",
            "snorkel-0.7.0-beta/tutorials/\n",
            "snorkel-0.7.0-beta/tutorials/README.md\n",
            "snorkel-0.7.0-beta/tutorials/advanced/\n",
            "snorkel-0.7.0-beta/tutorials/advanced/BRAT_Annotations.ipynb\n",
            "snorkel-0.7.0-beta/tutorials/advanced/Categorical_Classes.ipynb\n",
            "snorkel-0.7.0-beta/tutorials/advanced/Elastic_Search.ipynb\n",
            "snorkel-0.7.0-beta/tutorials/advanced/Hyperparameter_Search.ipynb\n",
            "snorkel-0.7.0-beta/tutorials/advanced/Parallel_Processing.ipynb\n",
            "snorkel-0.7.0-beta/tutorials/advanced/README.md\n",
            "snorkel-0.7.0-beta/tutorials/advanced/Structure_Learning.ipynb\n",
            "snorkel-0.7.0-beta/tutorials/advanced/checkpoints/\n",
            "snorkel-0.7.0-beta/tutorials/advanced/checkpoints/spouse.lstm/\n",
            "snorkel-0.7.0-beta/tutorials/advanced/checkpoints/spouse.lstm/checkpoint\n",
            "snorkel-0.7.0-beta/tutorials/advanced/checkpoints/spouse.lstm/model_kwargs.pkl\n",
            "snorkel-0.7.0-beta/tutorials/advanced/checkpoints/spouse.lstm/spouse.lstm-0.data-00000-of-00001\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "snorkel-0.7.0-beta/tutorials/advanced/checkpoints/spouse.lstm/spouse.lstm-0.index\n",
            "snorkel-0.7.0-beta/tutorials/advanced/checkpoints/spouse.lstm/spouse.lstm-0.meta\n",
            "snorkel-0.7.0-beta/tutorials/advanced/data/\n",
            "snorkel-0.7.0-beta/tutorials/advanced/data/brat_spouse.zip\n",
            "snorkel-0.7.0-beta/tutorials/advanced/data/brat_test_docs.tsv\n",
            "snorkel-0.7.0-beta/tutorials/advanced/data/categorical_example.tsv\n",
            "snorkel-0.7.0-beta/tutorials/advanced/elastics.py\n",
            "snorkel-0.7.0-beta/tutorials/advanced/imgs/\n",
            "snorkel-0.7.0-beta/tutorials/advanced/imgs/brat-anno-dialog.jpg\n",
            "snorkel-0.7.0-beta/tutorials/advanced/imgs/brat-login.jpg\n",
            "snorkel-0.7.0-beta/tutorials/advanced/imgs/brat-relation.jpg\n",
            "snorkel-0.7.0-beta/tutorials/cdr/\n",
            "snorkel-0.7.0-beta/tutorials/cdr/CDR_Tutorial_1.ipynb\n",
            "snorkel-0.7.0-beta/tutorials/cdr/CDR_Tutorial_2.ipynb\n",
            "snorkel-0.7.0-beta/tutorials/cdr/CDR_Tutorial_3.ipynb\n",
            "snorkel-0.7.0-beta/tutorials/cdr/README.md\n",
            "snorkel-0.7.0-beta/tutorials/cdr/data/\n",
            "snorkel-0.7.0-beta/tutorials/cdr/data/CDR.BioC.small.xml\n",
            "snorkel-0.7.0-beta/tutorials/cdr/data/cdr_relations_gold.pkl\n",
            "snorkel-0.7.0-beta/tutorials/cdr/data/chem_dis_mesh_dicts.pkl.bz2\n",
            "snorkel-0.7.0-beta/tutorials/cdr/data/ctd.pkl.bz2\n",
            "snorkel-0.7.0-beta/tutorials/cdr/data/doc_ids.pkl\n",
            "snorkel-0.7.0-beta/tutorials/cdr/data/taggerone_unary_tags_cdr.pkl.bz2\n",
            "snorkel-0.7.0-beta/tutorials/cdr/data/unary_tags.pkl.bz2\n",
            "snorkel-0.7.0-beta/tutorials/cdr/download_data.sh\n",
            "snorkel-0.7.0-beta/tutorials/cdr/id_script.py\n",
            "snorkel-0.7.0-beta/tutorials/cdr/load_external_annotations.py\n",
            "snorkel-0.7.0-beta/tutorials/cdr/snorkel.CDR_1.db.tar.gz\n",
            "snorkel-0.7.0-beta/tutorials/cdr/utils.py\n",
            "snorkel-0.7.0-beta/tutorials/crowdsourcing/\n",
            "snorkel-0.7.0-beta/tutorials/crowdsourcing/Crowdsourced_Sentiment_Analysis.ipynb\n",
            "snorkel-0.7.0-beta/tutorials/crowdsourcing/data/\n",
            "snorkel-0.7.0-beta/tutorials/crowdsourcing/data/weather-evaluated-agg-DFE.csv\n",
            "snorkel-0.7.0-beta/tutorials/crowdsourcing/data/weather-non-agg-DFE.csv\n",
            "snorkel-0.7.0-beta/tutorials/intro/\n",
            "snorkel-0.7.0-beta/tutorials/intro/Intro_Tutorial_1.ipynb\n",
            "snorkel-0.7.0-beta/tutorials/intro/Intro_Tutorial_2.ipynb\n",
            "snorkel-0.7.0-beta/tutorials/intro/Intro_Tutorial_3.ipynb\n",
            "snorkel-0.7.0-beta/tutorials/intro/README.md\n",
            "snorkel-0.7.0-beta/tutorials/intro/data/\n",
            "snorkel-0.7.0-beta/tutorials/intro/data/LICENSE\n",
            "snorkel-0.7.0-beta/tutorials/intro/data/articles.tsv\n",
            "snorkel-0.7.0-beta/tutorials/intro/data/gold_labels.tsv\n",
            "snorkel-0.7.0-beta/tutorials/intro/data/spouses_dbpedia.csv.bz2\n",
            "snorkel-0.7.0-beta/tutorials/intro/util.py\n",
            "snorkel-0.7.0-beta/tutorials/snark/\n",
            "snorkel-0.7.0-beta/tutorials/snark/Snark Tutorial.ipynb\n",
            "snorkel-0.7.0-beta/tutorials/workshop/\n",
            "snorkel-0.7.0-beta/tutorials/workshop/README.md\n",
            "snorkel-0.7.0-beta/tutorials/workshop/Workshop_1_Snorkel_API.ipynb\n",
            "snorkel-0.7.0-beta/tutorials/workshop/Workshop_2_Writing_Labeling_Functions.ipynb\n",
            "snorkel-0.7.0-beta/tutorials/workshop/Workshop_3_Generative_Model_Training.ipynb\n",
            "snorkel-0.7.0-beta/tutorials/workshop/Workshop_4_Discriminative_Model_Training.ipynb\n",
            "snorkel-0.7.0-beta/tutorials/workshop/Workshop_5_Advanced_Preprocessing.ipynb\n",
            "snorkel-0.7.0-beta/tutorials/workshop/Workshop_6_Advanced_Grid_Search.ipynb\n",
            "snorkel-0.7.0-beta/tutorials/workshop/Workshop_7_Advanced_BRAT_Annotator.ipynb\n",
            "snorkel-0.7.0-beta/tutorials/workshop/data/\n",
            "snorkel-0.7.0-beta/tutorials/workshop/data/LICENSE\n",
            "snorkel-0.7.0-beta/tutorials/workshop/data/articles.tsv\n",
            "snorkel-0.7.0-beta/tutorials/workshop/data/articles2.tsv\n",
            "snorkel-0.7.0-beta/tutorials/workshop/data/articles3.tsv\n",
            "snorkel-0.7.0-beta/tutorials/workshop/data/articles4.tsv\n",
            "snorkel-0.7.0-beta/tutorials/workshop/data/brat-spouse.zip\n",
            "snorkel-0.7.0-beta/tutorials/workshop/data/brat_test_docs.tsv\n",
            "snorkel-0.7.0-beta/tutorials/workshop/data/categorical_example.tsv\n",
            "snorkel-0.7.0-beta/tutorials/workshop/data/gold_labels.tsv\n",
            "snorkel-0.7.0-beta/tutorials/workshop/data/spouses_dbpedia.csv.bz2\n",
            "snorkel-0.7.0-beta/tutorials/workshop/imgs/\n",
            "snorkel-0.7.0-beta/tutorials/workshop/imgs/brat-anno-dialog.jpg\n",
            "snorkel-0.7.0-beta/tutorials/workshop/imgs/brat-login.jpg\n",
            "snorkel-0.7.0-beta/tutorials/workshop/imgs/brat-relation.jpg\n",
            "snorkel-0.7.0-beta/tutorials/workshop/imgs/candidate.jpg\n",
            "snorkel-0.7.0-beta/tutorials/workshop/imgs/context-hierarchy.jpg\n",
            "snorkel-0.7.0-beta/tutorials/workshop/imgs/hazy.jpg\n",
            "snorkel-0.7.0-beta/tutorials/workshop/imgs/logo.jpg\n",
            "snorkel-0.7.0-beta/tutorials/workshop/imgs/marginals-common.jpg\n",
            "snorkel-0.7.0-beta/tutorials/workshop/imgs/marginals-ideal.jpg\n",
            "snorkel-0.7.0-beta/tutorials/workshop/imgs/marginals-real.jpg\n",
            "snorkel-0.7.0-beta/tutorials/workshop/imgs/mobilize.jpg\n",
            "snorkel-0.7.0-beta/tutorials/workshop/imgs/person.jpg\n",
            "snorkel-0.7.0-beta/tutorials/workshop/imgs/sentence.jpg\n",
            "snorkel-0.7.0-beta/tutorials/workshop/imgs/spouse.jpg\n",
            "snorkel-0.7.0-beta/tutorials/workshop/lib/\n",
            "snorkel-0.7.0-beta/tutorials/workshop/lib/__init__.py\n",
            "snorkel-0.7.0-beta/tutorials/workshop/lib/dbpedia.py\n",
            "snorkel-0.7.0-beta/tutorials/workshop/lib/features.py\n",
            "snorkel-0.7.0-beta/tutorials/workshop/lib/init.py\n",
            "snorkel-0.7.0-beta/tutorials/workshop/lib/lf_factories.py\n",
            "snorkel-0.7.0-beta/tutorials/workshop/lib/load_external_annotations.py\n",
            "snorkel-0.7.0-beta/tutorials/workshop/lib/mp_lf.py\n",
            "snorkel-0.7.0-beta/tutorials/workshop/lib/scoring.py\n",
            "snorkel-0.7.0-beta/tutorials/workshop/lib/tree_structs_ipynb.py\n",
            "snorkel-0.7.0-beta/tutorials/workshop/lib/util.py\n",
            "snorkel-0.7.0-beta/tutorials/workshop/lib/vis/\n",
            "snorkel-0.7.0-beta/tutorials/workshop/lib/vis/tree-chart.html\n",
            "snorkel-0.7.0-beta/tutorials/workshop/lib/vis/tree-chart.js\n",
            "snorkel-0.7.0-beta/tutorials/workshop/lib/viz.py\n",
            "snorkel-0.7.0-beta/tutorials/workshop/slides/\n",
            "snorkel-0.7.0-beta/tutorials/workshop/slides/Snorkel-Workshop-FINAL.pdf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ruFOOPYJxKIh",
        "colab_type": "code",
        "colab": {},
        "outputId": "996b5211-bc67-4746-ba15-e1c795e329c1"
      },
      "source": [
        "!pip install snorkel-0.7.0-beta/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing ./snorkel-0.7.0-beta\n",
            "Building wheels for collected packages: snorkel\n",
            "  Building wheel for snorkel (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for snorkel: filename=snorkel-0.7.0b0-py3-none-any.whl size=149106 sha256=b1c3dcbe0b68bd64dc5561c96b326358a45dbf0f8e1af05bef992b9fa401519b\n",
            "  Stored in directory: /root/.cache/pip/wheels/70/d4/91/ff7b3cd6b6b5b9d20a3f51d7641ee561e8425d259bdb767fa1\n",
            "Successfully built snorkel\n",
            "Installing collected packages: snorkel\n",
            "Successfully installed snorkel-0.7.0b0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8eI18JkXxKIt",
        "colab_type": "text"
      },
      "source": [
        "## Creating a development set\n",
        "\n",
        "Before you proceed with task 1.1, we need to preprocess our documents using `Snorkel` utilities, parsing them into a simple hierarchy of component parts of our input data, which we refer as _contexts_. We'll also create _candidates_ out of these contexts, which are the objects we want to classify, in this case, possible mentions of schools and colleges that the cast have attended. Finally, we'll load some gold labels for evaluation.\n",
        "\n",
        "All of this preprocessed input data is saved to a database. In Snorkel, if no database is specified, then a SQLite database at `./snorkel.db` is created by default -- so no setup is needed here!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "QhYXTf_BxKI0",
        "colab_type": "code",
        "colab": {},
        "outputId": "d030500f-39ea-4ecd-c1e6-e3dd8956fb07"
      },
      "source": [
        "# ** STUDENT CODE\n",
        "\n",
        "import numpy as np, os\n",
        "from pathlib import Path\n",
        "from snorkel import SnorkelSession\n",
        "from snorkel.parser import TSVDocPreprocessor, CorpusParser\n",
        "from snorkel.parser.spacy_parser import Spacy\n",
        "from snorkel.models import Document, Sentence, candidate_subclass\n",
        "from snorkel.viewer import SentenceNgramViewer\n",
        "from snorkel.annotations import LabelAnnotator, load_gold_labels\n",
        "from utils import reload_external_labels, save_gold_labels, save_predicted_relations, \\\n",
        "     save_gold_relations, get_dev_doc_ids, get_test_doc_ids, get_gold_labels, number_of_people\n",
        "import pickle\n",
        "\n",
        "# TODO: Set location where you store your homework 5 files\n",
        "'''if 'HW_DIR' not in os.environ:\n",
        "    HW_DIR = Path(\"/.../Homework05\")\n",
        "else:\n",
        "    HW_DIR = Path(os.environ['HW_DIR'])\n",
        "    assert HW_DIR.exists()'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'if \\'HW_DIR\\' not in os.environ:\\n    HW_DIR = Path(\"/.../Homework05\")\\nelse:\\n    HW_DIR = Path(os.environ[\\'HW_DIR\\'])\\n    assert HW_DIR.exists()'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5t7r8SkxxKJE",
        "colab_type": "text"
      },
      "source": [
        "**Initializing a `SnorkelSession`**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "rU5xHAvaxKJI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline\n",
        "\n",
        "session = SnorkelSession()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkPegfS3xKJZ",
        "colab_type": "text"
      },
      "source": [
        "**Loading the Corpus**\n",
        "\n",
        "Next, we load and pre-process the corpus of documents."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "bIs6JTyhxKJd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "doc_preprocessor = TSVDocPreprocessor('cast_bios.tsv')\n",
        "#os.chdir('/kaggle/working')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yeaGeaxxKJw",
        "colab_type": "text"
      },
      "source": [
        "**Running a `CorpusParser`**\n",
        "\n",
        "We'll use [Spacy](https://spacy.io/), an NLP preprocessing tool, to split our documents into sentences and tokens, and provide named entity annotations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "j5JP33InxKJ1",
        "colab_type": "code",
        "colab": {},
        "outputId": "73eeb03e-2244-4478-d904-dec26583e0e4"
      },
      "source": [
        "corpus_parser = CorpusParser(parser=Spacy())\n",
        "%time corpus_parser.apply(doc_preprocessor)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clearing existing...\n",
            "Running UDF...\n",
            "CPU times: user 47.6 s, sys: 245 ms, total: 47.9 s\n",
            "Wall time: 48 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "we9yxYhrxKKA",
        "colab_type": "text"
      },
      "source": [
        "We can then use simple database queries (written in the syntax of [SQLAlchemy](http://www.sqlalchemy.org/), which Snorkel uses) to check how many documents and sentences were parsed:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "YutJSClHxKKF",
        "colab_type": "code",
        "colab": {},
        "outputId": "a1e983c0-cbe6-4691-e180-655939fde0f2"
      },
      "source": [
        "print(\"Documents:\", session.query(Document).count())\n",
        "print(\"Sentences:\", session.query(Sentence).count())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Documents: 1423\n",
            "Sentences: 8137\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZuPumEeyxKKM",
        "colab_type": "text"
      },
      "source": [
        "**Generating Candidates**\n",
        "\n",
        "The next step is to extract _candidates_ from our corpus. A `Candidate` in Snorkel is an object for which we want to make a prediction. In this case, the candidates are pairs of person and organization mentioned in sentences.\n",
        "\n",
        "The [Spacy](https://spacy.io/) parser we used performs _named entity recognition_ for us. Next, we'll split up the documents into train, development, and test splits; and collect the associated sentences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "5BnPppkKxKKO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Education = candidate_subclass('Education', ['person', 'organization'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "6DKS_J1wxKKW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from snorkel.candidates import Ngrams, CandidateExtractor\n",
        "from snorkel.matchers import PersonMatcher, OrganizationMatcher\n",
        "\n",
        "ngrams         = Ngrams(n_max=7)\n",
        "person_matcher = PersonMatcher(longest_match_only=True)\n",
        "org_matcher    = OrganizationMatcher(longest_match_only=True)\n",
        "cand_extractor = CandidateExtractor(Education, [ngrams, ngrams], [person_matcher, org_matcher])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "fTP-Ft2fxKKf",
        "colab_type": "code",
        "colab": {},
        "outputId": "ea9469ac-8a58-4aba-d1c3-5add5131ac03"
      },
      "source": [
        "docs = session.query(Document).order_by(Document.name).all()\n",
        "\n",
        "dev_docs = get_dev_doc_ids(\"cast.dev.txt\")\n",
        "test_docs = get_test_doc_ids(\"cast.test.txt\")\n",
        "\n",
        "train_sents = set()\n",
        "dev_sents   = set()\n",
        "test_sents  = set()\n",
        "\n",
        "for doc in docs:\n",
        "    sents = (s for s in doc.sentences if number_of_people(s) <= 5)\n",
        "    if doc.name in dev_docs:\n",
        "        dev_sents.update(sents)\n",
        "    elif doc.name in test_docs:\n",
        "        test_sents.update(sents)\n",
        "    else:\n",
        "        train_sents.update(sents)\n",
        "        \n",
        "print(\"Number of dev sents:\", len(dev_sents))\n",
        "print(\"Number of train sents:\", len(train_sents))\n",
        "print(\"Number of test sents:\", len(test_sents))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of dev sents: 591\n",
            "Number of train sents: 5711\n",
            "Number of test sents: 1808\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFZfJ2r6xKKu",
        "colab_type": "text"
      },
      "source": [
        "Finally, we'll apply the candidate extractor to the three sets of sentences. The results will be persisted in the database backend."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "beUIxethxKKy",
        "colab_type": "code",
        "colab": {},
        "outputId": "d12db88d-3a76-42b8-9f83-4357b546b935"
      },
      "source": [
        "%%time\n",
        "for i, sents in enumerate([train_sents, dev_sents, test_sents]):\n",
        "    cand_extractor.apply(sents, split=i)\n",
        "    print(\"Number of candidates:\", session.query(Education).filter(Education.split == i).count())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clearing existing...\n",
            "Running UDF...\n",
            "[========================================] 100%\n",
            "\n",
            "Number of candidates: 2074\n",
            "Clearing existing...\n",
            "Running UDF...\n",
            "[========================================] 100%\n",
            "\n",
            "Number of candidates: 227\n",
            "Clearing existing...\n",
            "Running UDF...\n",
            "[========================================] 100%\n",
            "\n",
            "Number of candidates: 537\n",
            "CPU times: user 59.7 s, sys: 358 ms, total: 1min\n",
            "Wall time: 59.8 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bp3PK-9UxKK5",
        "colab_type": "text"
      },
      "source": [
        "## Task 1.1. Label 99 documents in development set\n",
        "\n",
        "In this task, you will use `SentenceNgramViewer` to label each mention. You can click the green button to mark the candidate as correct, red button to mark as incorrect. Your labeling result is automatically stored in the database."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "F_Z4gOWuxKK7",
        "colab_type": "code",
        "colab": {},
        "outputId": "f76dbcb3-0355-40ad-c459-ba86b8c2f056"
      },
      "source": [
        "gold_labels = get_gold_labels(session)\n",
        "labeled_sents = {lbl.candidate.person.sentence.id for lbl in gold_labels}\n",
        "unlabeled = [\n",
        "    x for x in session.query(Education).filter(Education.split == 1).all() \n",
        "    if x.person.sentence.id not in labeled_sents\n",
        "]\n",
        "print(\"Number unlabeled:\", len(unlabeled))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number unlabeled: 227\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "9PvLVP8vxKK_",
        "colab_type": "code",
        "colab": {
          "referenced_widgets": [
            "71ffe25e8a8045d5a2eac46dfca01239"
          ]
        },
        "outputId": "a164871f-ba13-48a4-9cd4-ab82261e8873"
      },
      "source": [
        "\n",
        "SentenceNgramViewer(unlabeled, session, annotator_name=\"gold\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "require.undef('viewer');\n",
              "\n",
              "// NOTE: all elements should be selected using this.$el.find to avoid collisions with other Viewers\n",
              "\n",
              "define('viewer', [\"@jupyter-widgets/base\"], function(widgets) {\n",
              "    var ViewerView = widgets.DOMWidgetView.extend({\n",
              "        render: function() {\n",
              "            this.cids   = this.model.get('cids');\n",
              "            this.nPages = this.cids.length;\n",
              "            this.pid  = 0;\n",
              "            this.cxid = 0;\n",
              "            this.cid  = 0;\n",
              "\n",
              "            // Insert the html payload\n",
              "            this.$el.append(this.model.get('html'));\n",
              "\n",
              "            // Initialize all labels from previous sessions\n",
              "            this.labels = this.deserializeDict(this.model.get('_labels_serialized'));\n",
              "            for (var i=0; i < this.nPages; i++) {\n",
              "                this.pid = i;\n",
              "                for (var j=0; j < this.cids[i].length; j++) {\n",
              "                    this.cxid = j;\n",
              "                    for (var k=0; k < this.cids[i][j].length; k++) {\n",
              "                        this.cid = k;\n",
              "                        if (this.cids[i][j][k] in this.labels) {\n",
              "                            this.markCurrentCandidate(false);\n",
              "                        }\n",
              "                    }\n",
              "                }\n",
              "            }\n",
              "            this.pid  = 0;\n",
              "            this.cxid = 0;\n",
              "            this.cid  = 0;\n",
              "\n",
              "            // Enable button functionality for navigation\n",
              "            var that = this;\n",
              "            this.$el.find(\"#next-cand\").click(function() {\n",
              "                that.switchCandidate(1);\n",
              "            });\n",
              "            this.$el.find(\"#prev-cand\").click(function() {\n",
              "                that.switchCandidate(-1);\n",
              "            });\n",
              "            this.$el.find(\"#next-context\").click(function() {\n",
              "                that.switchContext(1);\n",
              "            });\n",
              "            this.$el.find(\"#prev-context\").click(function() {\n",
              "                that.switchContext(-1);\n",
              "            });\n",
              "            this.$el.find(\"#next-page\").click(function() {\n",
              "                that.switchPage(1);\n",
              "            });\n",
              "            this.$el.find(\"#prev-page\").click(function() {\n",
              "                that.switchPage(-1);\n",
              "            });\n",
              "            this.$el.find(\"#label-true\").click(function() {\n",
              "                that.labelCandidate(true, true);\n",
              "            });\n",
              "            this.$el.find(\"#label-false\").click(function() {\n",
              "                that.labelCandidate(false, true);\n",
              "            });\n",
              "\n",
              "            // Arrow key functionality\n",
              "            this.$el.keydown(function(e) {\n",
              "                switch(e.which) {\n",
              "                    case 74: // j\n",
              "                    that.switchCandidate(-1);\n",
              "                    break;\n",
              "\n",
              "                    case 73: // i\n",
              "                    that.switchPage(-1);\n",
              "                    break;\n",
              "\n",
              "                    case 76: // l\n",
              "                    that.switchCandidate(1);\n",
              "                    break;\n",
              "\n",
              "                    case 75: // k\n",
              "                    that.switchPage(1);\n",
              "                    break;\n",
              "\n",
              "                    case 84: // t\n",
              "                    that.labelCandidate(true, true);\n",
              "                    break;\n",
              "\n",
              "                    case 70: // f\n",
              "                    that.labelCandidate(false, true);\n",
              "                    break;\n",
              "                }\n",
              "            });\n",
              "\n",
              "            // Show the first page and highlight the first candidate\n",
              "            this.$el.find(\"#viewer-page-0\").show();\n",
              "            this.switchCandidate(0);\n",
              "        },\n",
              "\n",
              "        // Get candidate selector for currently selected candidate, escaping id properly\n",
              "        getCandidate: function() {\n",
              "            return this.$el.find(\".\"+this.cids[this.pid][this.cxid][this.cid]);\n",
              "        },  \n",
              "\n",
              "        // Color the candidate correctly according to registered label, as well as set highlighting\n",
              "        markCurrentCandidate: function(highlight) {\n",
              "            var cid  = this.cids[this.pid][this.cxid][this.cid];\n",
              "            var tags = this.$el.find(\".\"+cid);\n",
              "\n",
              "            // Clear color classes\n",
              "            tags.removeClass(\"candidate-h\");\n",
              "            tags.removeClass(\"true-candidate\");\n",
              "            tags.removeClass(\"true-candidate-h\");\n",
              "            tags.removeClass(\"false-candidate\");\n",
              "            tags.removeClass(\"false-candidate-h\");\n",
              "            tags.removeClass(\"highlighted\");\n",
              "\n",
              "            if (highlight) {\n",
              "                if (cid in this.labels) {\n",
              "                    tags.addClass(String(this.labels[cid]) + \"-candidate-h\");\n",
              "                } else {\n",
              "                    tags.addClass(\"candidate-h\");\n",
              "                }\n",
              "            \n",
              "            // If un-highlighting, leave with first non-null coloring\n",
              "            } else {\n",
              "                var that = this;\n",
              "                tags.each(function() {\n",
              "                    var cids = $(this).attr('class').split(/\\s+/).map(function(item) {\n",
              "                        return parseInt(item);\n",
              "                    });\n",
              "                    cids.sort();\n",
              "                    for (var i in cids) {\n",
              "                        if (cids[i] in that.labels) {\n",
              "                            var label = that.labels[cids[i]];\n",
              "                            $(this).addClass(String(label) + \"-candidate\");\n",
              "                            $(this).removeClass(String(!label) + \"-candidate\");\n",
              "                            break;\n",
              "                        }\n",
              "                    }\n",
              "                });\n",
              "            }\n",
              "\n",
              "            // Extra highlighting css\n",
              "            if (highlight) {\n",
              "                tags.addClass(\"highlighted\");\n",
              "            }\n",
              "\n",
              "            // Classes for showing direction of relation\n",
              "            if (highlight) {\n",
              "                this.$el.find(\".\"+cid+\"-0\").addClass(\"left-candidate\");\n",
              "                this.$el.find(\".\"+cid+\"-1\").addClass(\"right-candidate\");\n",
              "            } else {\n",
              "                this.$el.find(\".\"+cid+\"-0\").removeClass(\"left-candidate\");\n",
              "                this.$el.find(\".\"+cid+\"-1\").removeClass(\"right-candidate\");\n",
              "            }\n",
              "        },\n",
              "\n",
              "        // Cycle through candidates and highlight, by increment inc\n",
              "        switchCandidate: function(inc) {\n",
              "            var N = this.cids[this.pid].length\n",
              "            var M = this.cids[this.pid][this.cxid].length;\n",
              "            if (N == 0 || M == 0) { return false; }\n",
              "\n",
              "            // Clear highlighting from previous candidate\n",
              "            if (inc != 0) {\n",
              "                this.markCurrentCandidate(false);\n",
              "\n",
              "                // Increment the cid counter\n",
              "\n",
              "                // Move to next context\n",
              "                if (this.cid + inc >= M) {\n",
              "                    while (this.cid + inc >= M) {\n",
              "                        \n",
              "                        // At last context on page, halt\n",
              "                        if (this.cxid == N - 1) {\n",
              "                            this.cid = M - 1;\n",
              "                            inc = 0;\n",
              "                            break;\n",
              "                        \n",
              "                        // Increment to next context\n",
              "                        } else {\n",
              "                            inc -= M - this.cid;\n",
              "                            this.cxid += 1;\n",
              "                            M = this.cids[this.pid][this.cxid].length;\n",
              "                            this.cid = 0;\n",
              "                        }\n",
              "                    }\n",
              "\n",
              "                // Move to previous context\n",
              "                } else if (this.cid + inc < 0) {\n",
              "                    while (this.cid + inc < 0) {\n",
              "                        \n",
              "                        // At first context on page, halt\n",
              "                        if (this.cxid == 0) {\n",
              "                            this.cid = 0;\n",
              "                            inc = 0;\n",
              "                            break;\n",
              "                        \n",
              "                        // Increment to previous context\n",
              "                        } else {\n",
              "                            inc += this.cid + 1;\n",
              "                            this.cxid -= 1;\n",
              "                            M = this.cids[this.pid][this.cxid].length;\n",
              "                            this.cid = M - 1;\n",
              "                        }\n",
              "                    }\n",
              "                }\n",
              "\n",
              "                // Move within current context\n",
              "                this.cid += inc;\n",
              "            }\n",
              "            this.markCurrentCandidate(true);\n",
              "\n",
              "            // Push this new cid to the model\n",
              "            this.model.set('_selected_cid', this.cids[this.pid][this.cxid][this.cid]);\n",
              "            this.touch();\n",
              "        },\n",
              "\n",
              "        // Switch through contexts\n",
              "        switchContext: function(inc) {\n",
              "            this.markCurrentCandidate(false);\n",
              "\n",
              "            // Iterate context on this page\n",
              "            var M = this.cids[this.pid].length;\n",
              "            if (this.cxid + inc < 0) {\n",
              "                this.cxid = 0;\n",
              "            } else if (this.cxid + inc >= M) {\n",
              "                this.cxid = M - 1;\n",
              "            } else {\n",
              "                this.cxid += inc;\n",
              "            }\n",
              "\n",
              "            // Reset cid and set to first candidate\n",
              "            this.cid = 0;\n",
              "            this.switchCandidate(0);\n",
              "        },\n",
              "\n",
              "        // Switch through pages\n",
              "        switchPage: function(inc) {\n",
              "            this.markCurrentCandidate(false);\n",
              "            this.$el.find(\".viewer-page\").hide();\n",
              "            if (this.pid + inc < 0) {\n",
              "                this.pid = 0;\n",
              "            } else if (this.pid + inc > this.nPages - 1) {\n",
              "                this.pid = this.nPages - 1;\n",
              "            } else {\n",
              "                this.pid += inc;\n",
              "            }\n",
              "            this.$el.find(\"#viewer-page-\"+this.pid).show();\n",
              "\n",
              "            // Show pagination\n",
              "            this.$el.find(\"#page\").html(this.pid);\n",
              "\n",
              "            // Reset cid and set to first candidate\n",
              "            this.cid = 0;\n",
              "            this.cxid = 0;\n",
              "            this.switchCandidate(0);\n",
              "        },\n",
              "\n",
              "        // Label currently-selected candidate\n",
              "        labelCandidate: function(label, highlighted) {\n",
              "            var c    = this.getCandidate();\n",
              "            var cid  = this.cids[this.pid][this.cxid][this.cid];\n",
              "            var cl   = String(label) + \"-candidate\";\n",
              "            var clh  = String(label) + \"-candidate-h\";\n",
              "            var cln  = String(!label) + \"-candidate\";\n",
              "            var clnh = String(!label) + \"-candidate-h\";\n",
              "\n",
              "            // Toggle label highlighting\n",
              "            if (c.hasClass(cl) || c.hasClass(clh)) {\n",
              "                c.removeClass(cl);\n",
              "                c.removeClass(clh);\n",
              "                if (highlighted) {\n",
              "                    c.addClass(\"candidate-h\");\n",
              "                }\n",
              "                this.labels[cid] = null;\n",
              "                this.send({event: 'delete_label', cid: cid});\n",
              "            } else {\n",
              "                c.removeClass(cln);\n",
              "                c.removeClass(clnh);\n",
              "                if (highlighted) {\n",
              "                    c.addClass(clh);\n",
              "                } else {\n",
              "                    c.addClass(cl);\n",
              "                }\n",
              "                this.labels[cid] = label;\n",
              "                this.send({event: 'set_label', cid: cid, value: label});\n",
              "            }\n",
              "\n",
              "            // Set the label and pass back to the model\n",
              "            this.model.set('_labels_serialized', this.serializeDict(this.labels));\n",
              "            this.touch();\n",
              "        },\n",
              "\n",
              "        // Serialization of hash maps, because traitlets Dict doesn't seem to work...\n",
              "        serializeDict: function(d) {\n",
              "            var s = [];\n",
              "            for (var key in d) {\n",
              "                s.push(key+\"~~\"+d[key]);\n",
              "            }\n",
              "            return s.join();\n",
              "        },\n",
              "\n",
              "        // Deserialization of hash maps\n",
              "        deserializeDict: function(s) {\n",
              "            var d = {};\n",
              "            var entries = s.split(/,/);\n",
              "            var kv;\n",
              "            for (var i in entries) {\n",
              "                kv = entries[i].split(/~~/);\n",
              "                if (kv[1] == \"true\") {\n",
              "                    d[kv[0]] = true;\n",
              "                } else if (kv[1] == \"false\") {\n",
              "                    d[kv[0]] = false;\n",
              "                }\n",
              "            }\n",
              "            return d;\n",
              "        },\n",
              "    });\n",
              "\n",
              "    return {\n",
              "        ViewerView: ViewerView\n",
              "    };\n",
              "});\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "SentenceNgramViewer(cids=[[[27, 141, 156, 216], [135], [82, 104]], [[107, 142], [43], [196, 197, 198]], [[21, …"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "71ffe25e8a8045d5a2eac46dfca01239"
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0aqfefhxKLF",
        "colab_type": "text"
      },
      "source": [
        "After you finish labeling, executing the cell below to **save your result** to JSON files. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "YKdksczKxKLS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ** STUDENT CODE\n",
        "# TODO: change to your name\n",
        "save_gold_labels(session, \"Rijul_Vohra_hw05_gold_labels.dev_3-11_18_35.json\", split=1)\n",
        "save_gold_relations(session, \"Rijul_Vohra_hw05_extracted_relation.dev_3-11_18_35.json\", split=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gR3mneyZxKLZ",
        "colab_type": "text"
      },
      "source": [
        "## Tasks 1.2 & 1.3: Define labeling functions (LFs)\n",
        "\n",
        "In this task, you will define your own LFs, which Snorkel uses to create noise-aware training set. Usually, you will go through a couple of iterations (create LFs, test and refine it) to come up with a good set of LFs. We provide you at the end of this section a helper to quickly see what candidates did your model fail to classify. You can refer to Snorkel tutorial or online documentation for more information."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkzP5pKuxKLa",
        "colab_type": "text"
      },
      "source": [
        "You are free to use write any extra code to create a set of sophisticated LFs. For example, you build a list of universities and check if it matches with your candidate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "rF35D0cTxKLc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from SPARQLWrapper import SPARQLWrapper, JSON\n",
        "# Educational Institutions\n",
        "sparql = SPARQLWrapper(\"http://dbpedia.org/sparql\")\n",
        "offset = 0\n",
        "educational_inst = []\n",
        "while True:\n",
        "    prev_offset = offset\n",
        "    st = time.time()\n",
        "    sparql.setQuery(\"\"\"\n",
        "    PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
        "    PREFIX dbo: <http://dbpedia.org/ontology/>\n",
        "    SELECT ?label\n",
        "    WHERE \n",
        "    {\n",
        "    ?college a dbo:EducationalInstitution .\n",
        "    ?college rdfs:label ?label .\n",
        "    FILTER(lang(?label) = 'en')\n",
        "    }\n",
        "    offset %s\n",
        "    limit 10000\n",
        "    \"\"\" % str(offset))\n",
        "    sparql.setReturnFormat(JSON)\n",
        "    results = sparql.query().convert()\n",
        "    for result in results[\"results\"][\"bindings\"]:\n",
        "        educational_inst.append(result['label']['value'])\n",
        "    offset = len(educational_inst)\n",
        "    if prev_offset == offset:\n",
        "        break\n",
        "\n",
        "pickle.dump(educational_inst,open('educational_db.pkl','wb'))\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "xuPwxesVxKLh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Actors\n",
        "sparql = SPARQLWrapper(\"http://dbpedia.org/sparql\")\n",
        "offset = 0\n",
        "actor_list = []\n",
        "while True:\n",
        "    prev_offset = offset\n",
        "    st = time.time()\n",
        "    sparql.setQuery(\"\"\"\n",
        "    PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
        "    PREFIX dbo: <http://dbpedia.org/ontology/>\n",
        "    SELECT ?label\n",
        "    WHERE \n",
        "    {\n",
        "\n",
        "    ?actor a yago:Actor109765278 .\n",
        "    ?actor rdfs:label ?label\n",
        "    FILTER(lang(?label) = 'en')\n",
        "    }\n",
        "    offset %s\n",
        "    limit 10000\n",
        "    \"\"\" % str(offset))\n",
        "    sparql.setReturnFormat(JSON)\n",
        "    results = sparql.query().convert()\n",
        "    for result in results[\"results\"][\"bindings\"]:\n",
        "        actor_list.append(result['label']['value'])\n",
        "    offset = len(actor_list)\n",
        "    if prev_offset == offset:\n",
        "        break\n",
        "pickle.dump(actor_list,open('actor_db.pkl','wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Kzi6t_O8xKLu",
        "colab_type": "code",
        "colab": {},
        "outputId": "2fdc43fc-b00a-4c9a-db0b-d6bb8eff58d2"
      },
      "source": [
        "# ** STUDENT CODE \n",
        "\n",
        "# These are some example snorkel helpers you can use...\n",
        "os.chdir('/kaggle/input/dbpedia-groundtruth')\n",
        "from snorkel.lf_helpers import (\n",
        "    get_left_tokens, get_right_tokens, get_between_tokens,\n",
        "    get_text_between, get_tagged_text,contains_token\n",
        ")\n",
        "\n",
        "# TODO: Define your LFs here, below is a very simple LF\n",
        "\n",
        "tokens = set([\"studied\",\"trained\",\"schooling\",\"graduated\",\"attended\",\"study\",\"studying\",\"enrolled\",\"bachelor's\"])\n",
        "negative_tokens = set([\"actress\",\"roles\",\"cast\",\"starred\",\"appeared\",\"role\",\"directed\",\"nominated\",\"actor\",\"films\",'film'])\n",
        "educational_inst = pickle.load(open('educational_db.pkl','rb'))\n",
        "actor_list = pickle.load(open('actor_db.pkl','rb'))\n",
        "def LF_sample1(c):\n",
        "    l = set(get_between_tokens(c,attrib='words'))\n",
        "    #l = set(l)\n",
        "    if len(l.intersection(tokens)) > 0:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "def LF_sample2(c):\n",
        "    if contains_token(c.organization,\"University\") or contains_token(c.organization,\"School\") or contains_token(c.organization,\"College\"):\n",
        "        return 1\n",
        "    else:\n",
        "        return -1\n",
        "    \n",
        "def LF_sample3(c):\n",
        "    right_tokens = set(get_right_tokens(c))\n",
        "    if (len(right_tokens.intersection(tokens))) > 0:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "def LF_sample4(c):\n",
        "    between_tokens = set(get_between_tokens(c))\n",
        "    if len(between_tokens.intersection(negative_tokens)) > 1:\n",
        "        return -1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "def LF_sample5(c):\n",
        "    right_tokens = set(get_right_tokens(c))\n",
        "    if len(right_tokens.intersection(negative_tokens)) > 1:\n",
        "        return -1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "def LF_sample6(c):\n",
        "    left_tokens = set(get_left_tokens(c))\n",
        "    if len(left_tokens.intersection(negative_tokens)) > 1:\n",
        "        return -1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "def LF_sample7(c):\n",
        "    if c.organization.get_span() in educational_inst:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "    #print(c.person.get_span(),end = '\\t')\n",
        "    #print(c.organization.get_span())\n",
        "\n",
        "def LF_sample8(c):\n",
        "    if c.organization.get_span() in actor_list:\n",
        "        return -1\n",
        "    else:\n",
        "        0\n",
        "\n",
        "\n",
        "'''def LF_sample4(c):\n",
        "    left_tokens = set(get_left_tokens(c))\n",
        "    if (len(left_tokens.intersection(tokens))) > 0:\n",
        "        return 1\n",
        "    else:'''\n",
        " \n",
        "    \n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'def LF_sample4(c):\\n    left_tokens = set(get_left_tokens(c))\\n    if (len(left_tokens.intersection(tokens))) > 0:\\n        return 1\\n    else:'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Kr8eAaEUxKL6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ** STUDENT CODE\n",
        "\n",
        "# TODO: store all of your labeling functions into LFs\n",
        "\n",
        "#LFs = [LF_sample1,LF_sample2,LF_sample3,LF_sample4,LF_sample5]\n",
        "LFs = [LF_sample1,LF_sample2,LF_sample3,LF_sample4,LF_sample5,LF_sample6,LF_sample7,LF_sample8]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Xgzs5A4xKMA",
        "colab_type": "text"
      },
      "source": [
        "**Train generative model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "b9pVFd-5xKME",
        "colab_type": "code",
        "colab": {},
        "outputId": "5903b0cd-d3a7-4fb5-b123-5cd28cecf5f2"
      },
      "source": [
        "np.random.seed(1701)\n",
        "\n",
        "labeler = LabelAnnotator(lfs=LFs)\n",
        "L_train = labeler.apply(split=0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clearing existing...\n",
            "Running UDF...\n",
            "[========================================] 100%\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "qF8aML3dxKMQ",
        "colab_type": "code",
        "colab": {},
        "outputId": "9ee4d50f-d383-4053-dd50-30a4be8cb3af"
      },
      "source": [
        "from snorkel.learning import GenerativeModel\n",
        "\n",
        "gen_model = GenerativeModel()\n",
        "gen_model.train(L_train, epochs=100, decay=0.95, step_size=0.1 / L_train.shape[0], reg_param=1e-6)\n",
        "\n",
        "print(\"LF weights:\", gen_model.weights.lf_accuracy)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Inferred cardinality: 2\n",
            "LF weights: [0.08435157 1.68472809 0.0807909  0.11647212 0.06941406 0.08159606\n",
            " 0.10595099 0.10890566]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_-1h14rxKMU",
        "colab_type": "text"
      },
      "source": [
        "We now apply the generative model to the training candidates to get the noise-aware training label set. We'll refer to these as the training marginals:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "_wm2YEgSxKMc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_marginals = gen_model.marginals(L_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6OsJzg6xKMh",
        "colab_type": "text"
      },
      "source": [
        "We'll look at the distribution of the training marginals:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "obtq2rZpxKMj",
        "colab_type": "code",
        "colab": {},
        "outputId": "80809c21-6dca-4299-c889-c375cbf7137c"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.hist(train_marginals, bins=20)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejI-7lb-xKMs",
        "colab_type": "text"
      },
      "source": [
        "Now that we have learned the generative model, we will measure its performances using the provided test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "KY5xHjYxxKM2",
        "colab_type": "code",
        "colab": {},
        "outputId": "daabfb39-663b-4ec7-a525-ec38d650892a"
      },
      "source": [
        "# Load test-set first\n",
        "reload_external_labels(session, \"gold_labels.test.json\")\n",
        "L_gold_dev = load_gold_labels(session, annotator_name='gold', split=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AnnotatorLabels created: 0\n",
            "AnnotatorLabels created: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "bz07NfKHxKM9",
        "colab_type": "code",
        "colab": {},
        "outputId": "9937b985-4234-4e51-bb21-3a6c4d34e26a"
      },
      "source": [
        "\n",
        "L_dev = labeler.apply_existing(split=1)\n",
        "tp, fp, tn, fn = gen_model.error_analysis(session, L_dev, L_gold_dev)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clearing existing...\n",
            "Running UDF...\n",
            "[========================================] 100%\n",
            "\n",
            "========================================\n",
            "Scores (Un-adjusted)\n",
            "========================================\n",
            "Pos. class accuracy: 0.833\n",
            "Neg. class accuracy: 0.947\n",
            "Precision            0.577\n",
            "Recall               0.833\n",
            "F1                   0.682\n",
            "----------------------------------------\n",
            "TP: 15 | FP: 11 | TN: 198 | FN: 3\n",
            "========================================\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ik_6xU8gxKNE",
        "colab_type": "text"
      },
      "source": [
        "Get detailed statistics of LFs learned by the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "cM4lV2QbxKNL",
        "colab_type": "code",
        "colab": {},
        "outputId": "e2ac14ac-64ba-480d-98c2-4e158b90ae11"
      },
      "source": [
        "L_dev.lf_stats(session, L_gold_dev, gen_model.learned_lf_stats()['Accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            j  Coverage  Overlaps  Conflicts  TP  FP  FN   TN  Empirical Acc.  \\\n",
              "LF_sample1  0  0.101322  0.101322   0.039648   9  14   0    0        0.391304   \n",
              "LF_sample2  1  1.000000  0.224670   0.039648  15  11   3  197        0.938053   \n",
              "LF_sample3  2  0.004405  0.004405   0.000000   1   0   0    0        1.000000   \n",
              "LF_sample4  3  0.039648  0.039648   0.000000   0   0   0    9        1.000000   \n",
              "LF_sample5  4  0.000000  0.000000   0.000000   0   0   0    0             NaN   \n",
              "LF_sample6  5  0.022026  0.022026   0.000000   0   0   0    5        1.000000   \n",
              "LF_sample7  6  0.044053  0.044053   0.000000   7   3   0    0        0.700000   \n",
              "LF_sample8  7  0.057269  0.057269   0.000000   0   0   0   13        1.000000   \n",
              "\n",
              "            Learned Acc.  \n",
              "LF_sample1      0.543158  \n",
              "LF_sample2      0.964910  \n",
              "LF_sample3      0.538764  \n",
              "LF_sample4      0.559467  \n",
              "LF_sample5      0.541114  \n",
              "LF_sample6      0.535677  \n",
              "LF_sample7      0.553558  \n",
              "LF_sample8      0.546071  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>j</th>\n",
              "      <th>Coverage</th>\n",
              "      <th>Overlaps</th>\n",
              "      <th>Conflicts</th>\n",
              "      <th>TP</th>\n",
              "      <th>FP</th>\n",
              "      <th>FN</th>\n",
              "      <th>TN</th>\n",
              "      <th>Empirical Acc.</th>\n",
              "      <th>Learned Acc.</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>LF_sample1</th>\n",
              "      <td>0</td>\n",
              "      <td>0.101322</td>\n",
              "      <td>0.101322</td>\n",
              "      <td>0.039648</td>\n",
              "      <td>9</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.391304</td>\n",
              "      <td>0.543158</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LF_sample2</th>\n",
              "      <td>1</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.224670</td>\n",
              "      <td>0.039648</td>\n",
              "      <td>15</td>\n",
              "      <td>11</td>\n",
              "      <td>3</td>\n",
              "      <td>197</td>\n",
              "      <td>0.938053</td>\n",
              "      <td>0.964910</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LF_sample3</th>\n",
              "      <td>2</td>\n",
              "      <td>0.004405</td>\n",
              "      <td>0.004405</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.538764</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LF_sample4</th>\n",
              "      <td>3</td>\n",
              "      <td>0.039648</td>\n",
              "      <td>0.039648</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.559467</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LF_sample5</th>\n",
              "      <td>4</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.541114</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LF_sample6</th>\n",
              "      <td>5</td>\n",
              "      <td>0.022026</td>\n",
              "      <td>0.022026</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.535677</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LF_sample7</th>\n",
              "      <td>6</td>\n",
              "      <td>0.044053</td>\n",
              "      <td>0.044053</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.553558</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LF_sample8</th>\n",
              "      <td>7</td>\n",
              "      <td>0.057269</td>\n",
              "      <td>0.057269</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.546071</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 193
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFzPrvnzxKNW",
        "colab_type": "text"
      },
      "source": [
        "You might want to look at some examples in one of the error buckets to improve your LFs. For example, below is one of the false negatives that we did not correctly label as true mentions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "uqm1shdWxKNX",
        "colab_type": "code",
        "colab": {
          "referenced_widgets": [
            "8215a9ebf3574669a54da8b7d3699a6f"
          ]
        },
        "outputId": "236125d3-c662-4a85-dc0c-c306d8379ad8"
      },
      "source": [
        "SentenceNgramViewer(fn, session)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "require.undef('viewer');\n",
              "\n",
              "// NOTE: all elements should be selected using this.$el.find to avoid collisions with other Viewers\n",
              "\n",
              "define('viewer', [\"@jupyter-widgets/base\"], function(widgets) {\n",
              "    var ViewerView = widgets.DOMWidgetView.extend({\n",
              "        render: function() {\n",
              "            this.cids   = this.model.get('cids');\n",
              "            this.nPages = this.cids.length;\n",
              "            this.pid  = 0;\n",
              "            this.cxid = 0;\n",
              "            this.cid  = 0;\n",
              "\n",
              "            // Insert the html payload\n",
              "            this.$el.append(this.model.get('html'));\n",
              "\n",
              "            // Initialize all labels from previous sessions\n",
              "            this.labels = this.deserializeDict(this.model.get('_labels_serialized'));\n",
              "            for (var i=0; i < this.nPages; i++) {\n",
              "                this.pid = i;\n",
              "                for (var j=0; j < this.cids[i].length; j++) {\n",
              "                    this.cxid = j;\n",
              "                    for (var k=0; k < this.cids[i][j].length; k++) {\n",
              "                        this.cid = k;\n",
              "                        if (this.cids[i][j][k] in this.labels) {\n",
              "                            this.markCurrentCandidate(false);\n",
              "                        }\n",
              "                    }\n",
              "                }\n",
              "            }\n",
              "            this.pid  = 0;\n",
              "            this.cxid = 0;\n",
              "            this.cid  = 0;\n",
              "\n",
              "            // Enable button functionality for navigation\n",
              "            var that = this;\n",
              "            this.$el.find(\"#next-cand\").click(function() {\n",
              "                that.switchCandidate(1);\n",
              "            });\n",
              "            this.$el.find(\"#prev-cand\").click(function() {\n",
              "                that.switchCandidate(-1);\n",
              "            });\n",
              "            this.$el.find(\"#next-context\").click(function() {\n",
              "                that.switchContext(1);\n",
              "            });\n",
              "            this.$el.find(\"#prev-context\").click(function() {\n",
              "                that.switchContext(-1);\n",
              "            });\n",
              "            this.$el.find(\"#next-page\").click(function() {\n",
              "                that.switchPage(1);\n",
              "            });\n",
              "            this.$el.find(\"#prev-page\").click(function() {\n",
              "                that.switchPage(-1);\n",
              "            });\n",
              "            this.$el.find(\"#label-true\").click(function() {\n",
              "                that.labelCandidate(true, true);\n",
              "            });\n",
              "            this.$el.find(\"#label-false\").click(function() {\n",
              "                that.labelCandidate(false, true);\n",
              "            });\n",
              "\n",
              "            // Arrow key functionality\n",
              "            this.$el.keydown(function(e) {\n",
              "                switch(e.which) {\n",
              "                    case 74: // j\n",
              "                    that.switchCandidate(-1);\n",
              "                    break;\n",
              "\n",
              "                    case 73: // i\n",
              "                    that.switchPage(-1);\n",
              "                    break;\n",
              "\n",
              "                    case 76: // l\n",
              "                    that.switchCandidate(1);\n",
              "                    break;\n",
              "\n",
              "                    case 75: // k\n",
              "                    that.switchPage(1);\n",
              "                    break;\n",
              "\n",
              "                    case 84: // t\n",
              "                    that.labelCandidate(true, true);\n",
              "                    break;\n",
              "\n",
              "                    case 70: // f\n",
              "                    that.labelCandidate(false, true);\n",
              "                    break;\n",
              "                }\n",
              "            });\n",
              "\n",
              "            // Show the first page and highlight the first candidate\n",
              "            this.$el.find(\"#viewer-page-0\").show();\n",
              "            this.switchCandidate(0);\n",
              "        },\n",
              "\n",
              "        // Get candidate selector for currently selected candidate, escaping id properly\n",
              "        getCandidate: function() {\n",
              "            return this.$el.find(\".\"+this.cids[this.pid][this.cxid][this.cid]);\n",
              "        },  \n",
              "\n",
              "        // Color the candidate correctly according to registered label, as well as set highlighting\n",
              "        markCurrentCandidate: function(highlight) {\n",
              "            var cid  = this.cids[this.pid][this.cxid][this.cid];\n",
              "            var tags = this.$el.find(\".\"+cid);\n",
              "\n",
              "            // Clear color classes\n",
              "            tags.removeClass(\"candidate-h\");\n",
              "            tags.removeClass(\"true-candidate\");\n",
              "            tags.removeClass(\"true-candidate-h\");\n",
              "            tags.removeClass(\"false-candidate\");\n",
              "            tags.removeClass(\"false-candidate-h\");\n",
              "            tags.removeClass(\"highlighted\");\n",
              "\n",
              "            if (highlight) {\n",
              "                if (cid in this.labels) {\n",
              "                    tags.addClass(String(this.labels[cid]) + \"-candidate-h\");\n",
              "                } else {\n",
              "                    tags.addClass(\"candidate-h\");\n",
              "                }\n",
              "            \n",
              "            // If un-highlighting, leave with first non-null coloring\n",
              "            } else {\n",
              "                var that = this;\n",
              "                tags.each(function() {\n",
              "                    var cids = $(this).attr('class').split(/\\s+/).map(function(item) {\n",
              "                        return parseInt(item);\n",
              "                    });\n",
              "                    cids.sort();\n",
              "                    for (var i in cids) {\n",
              "                        if (cids[i] in that.labels) {\n",
              "                            var label = that.labels[cids[i]];\n",
              "                            $(this).addClass(String(label) + \"-candidate\");\n",
              "                            $(this).removeClass(String(!label) + \"-candidate\");\n",
              "                            break;\n",
              "                        }\n",
              "                    }\n",
              "                });\n",
              "            }\n",
              "\n",
              "            // Extra highlighting css\n",
              "            if (highlight) {\n",
              "                tags.addClass(\"highlighted\");\n",
              "            }\n",
              "\n",
              "            // Classes for showing direction of relation\n",
              "            if (highlight) {\n",
              "                this.$el.find(\".\"+cid+\"-0\").addClass(\"left-candidate\");\n",
              "                this.$el.find(\".\"+cid+\"-1\").addClass(\"right-candidate\");\n",
              "            } else {\n",
              "                this.$el.find(\".\"+cid+\"-0\").removeClass(\"left-candidate\");\n",
              "                this.$el.find(\".\"+cid+\"-1\").removeClass(\"right-candidate\");\n",
              "            }\n",
              "        },\n",
              "\n",
              "        // Cycle through candidates and highlight, by increment inc\n",
              "        switchCandidate: function(inc) {\n",
              "            var N = this.cids[this.pid].length\n",
              "            var M = this.cids[this.pid][this.cxid].length;\n",
              "            if (N == 0 || M == 0) { return false; }\n",
              "\n",
              "            // Clear highlighting from previous candidate\n",
              "            if (inc != 0) {\n",
              "                this.markCurrentCandidate(false);\n",
              "\n",
              "                // Increment the cid counter\n",
              "\n",
              "                // Move to next context\n",
              "                if (this.cid + inc >= M) {\n",
              "                    while (this.cid + inc >= M) {\n",
              "                        \n",
              "                        // At last context on page, halt\n",
              "                        if (this.cxid == N - 1) {\n",
              "                            this.cid = M - 1;\n",
              "                            inc = 0;\n",
              "                            break;\n",
              "                        \n",
              "                        // Increment to next context\n",
              "                        } else {\n",
              "                            inc -= M - this.cid;\n",
              "                            this.cxid += 1;\n",
              "                            M = this.cids[this.pid][this.cxid].length;\n",
              "                            this.cid = 0;\n",
              "                        }\n",
              "                    }\n",
              "\n",
              "                // Move to previous context\n",
              "                } else if (this.cid + inc < 0) {\n",
              "                    while (this.cid + inc < 0) {\n",
              "                        \n",
              "                        // At first context on page, halt\n",
              "                        if (this.cxid == 0) {\n",
              "                            this.cid = 0;\n",
              "                            inc = 0;\n",
              "                            break;\n",
              "                        \n",
              "                        // Increment to previous context\n",
              "                        } else {\n",
              "                            inc += this.cid + 1;\n",
              "                            this.cxid -= 1;\n",
              "                            M = this.cids[this.pid][this.cxid].length;\n",
              "                            this.cid = M - 1;\n",
              "                        }\n",
              "                    }\n",
              "                }\n",
              "\n",
              "                // Move within current context\n",
              "                this.cid += inc;\n",
              "            }\n",
              "            this.markCurrentCandidate(true);\n",
              "\n",
              "            // Push this new cid to the model\n",
              "            this.model.set('_selected_cid', this.cids[this.pid][this.cxid][this.cid]);\n",
              "            this.touch();\n",
              "        },\n",
              "\n",
              "        // Switch through contexts\n",
              "        switchContext: function(inc) {\n",
              "            this.markCurrentCandidate(false);\n",
              "\n",
              "            // Iterate context on this page\n",
              "            var M = this.cids[this.pid].length;\n",
              "            if (this.cxid + inc < 0) {\n",
              "                this.cxid = 0;\n",
              "            } else if (this.cxid + inc >= M) {\n",
              "                this.cxid = M - 1;\n",
              "            } else {\n",
              "                this.cxid += inc;\n",
              "            }\n",
              "\n",
              "            // Reset cid and set to first candidate\n",
              "            this.cid = 0;\n",
              "            this.switchCandidate(0);\n",
              "        },\n",
              "\n",
              "        // Switch through pages\n",
              "        switchPage: function(inc) {\n",
              "            this.markCurrentCandidate(false);\n",
              "            this.$el.find(\".viewer-page\").hide();\n",
              "            if (this.pid + inc < 0) {\n",
              "                this.pid = 0;\n",
              "            } else if (this.pid + inc > this.nPages - 1) {\n",
              "                this.pid = this.nPages - 1;\n",
              "            } else {\n",
              "                this.pid += inc;\n",
              "            }\n",
              "            this.$el.find(\"#viewer-page-\"+this.pid).show();\n",
              "\n",
              "            // Show pagination\n",
              "            this.$el.find(\"#page\").html(this.pid);\n",
              "\n",
              "            // Reset cid and set to first candidate\n",
              "            this.cid = 0;\n",
              "            this.cxid = 0;\n",
              "            this.switchCandidate(0);\n",
              "        },\n",
              "\n",
              "        // Label currently-selected candidate\n",
              "        labelCandidate: function(label, highlighted) {\n",
              "            var c    = this.getCandidate();\n",
              "            var cid  = this.cids[this.pid][this.cxid][this.cid];\n",
              "            var cl   = String(label) + \"-candidate\";\n",
              "            var clh  = String(label) + \"-candidate-h\";\n",
              "            var cln  = String(!label) + \"-candidate\";\n",
              "            var clnh = String(!label) + \"-candidate-h\";\n",
              "\n",
              "            // Toggle label highlighting\n",
              "            if (c.hasClass(cl) || c.hasClass(clh)) {\n",
              "                c.removeClass(cl);\n",
              "                c.removeClass(clh);\n",
              "                if (highlighted) {\n",
              "                    c.addClass(\"candidate-h\");\n",
              "                }\n",
              "                this.labels[cid] = null;\n",
              "                this.send({event: 'delete_label', cid: cid});\n",
              "            } else {\n",
              "                c.removeClass(cln);\n",
              "                c.removeClass(clnh);\n",
              "                if (highlighted) {\n",
              "                    c.addClass(clh);\n",
              "                } else {\n",
              "                    c.addClass(cl);\n",
              "                }\n",
              "                this.labels[cid] = label;\n",
              "                this.send({event: 'set_label', cid: cid, value: label});\n",
              "            }\n",
              "\n",
              "            // Set the label and pass back to the model\n",
              "            this.model.set('_labels_serialized', this.serializeDict(this.labels));\n",
              "            this.touch();\n",
              "        },\n",
              "\n",
              "        // Serialization of hash maps, because traitlets Dict doesn't seem to work...\n",
              "        serializeDict: function(d) {\n",
              "            var s = [];\n",
              "            for (var key in d) {\n",
              "                s.push(key+\"~~\"+d[key]);\n",
              "            }\n",
              "            return s.join();\n",
              "        },\n",
              "\n",
              "        // Deserialization of hash maps\n",
              "        deserializeDict: function(s) {\n",
              "            var d = {};\n",
              "            var entries = s.split(/,/);\n",
              "            var kv;\n",
              "            for (var i in entries) {\n",
              "                kv = entries[i].split(/~~/);\n",
              "                if (kv[1] == \"true\") {\n",
              "                    d[kv[0]] = true;\n",
              "                } else if (kv[1] == \"false\") {\n",
              "                    d[kv[0]] = false;\n",
              "                }\n",
              "            }\n",
              "            return d;\n",
              "        },\n",
              "    });\n",
              "\n",
              "    return {\n",
              "        ViewerView: ViewerView\n",
              "    };\n",
              "});\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "SentenceNgramViewer(cids=[[[0], [1, 2]]], html='<head>\\n<style>\\nspan.candidate {\\n    background-color: rgba(…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8215a9ebf3574669a54da8b7d3699a6f"
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWRw_FAIxKNe",
        "colab_type": "text"
      },
      "source": [
        "## Task 1.4. Training an End Extraction Model\n",
        "\n",
        "In this final task, we'll use the noisy training labels we generated to train our end extraction model. In particular, we will be training a Bi-LSTM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "3l3_t45SxKNf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_cands = session.query(Education).filter(Education.split == 0).order_by(Education.id).all()\n",
        "dev_cands   = session.query(Education).filter(Education.split == 1).order_by(Education.id).all()\n",
        "test_cands  = session.query(Education).filter(Education.split == 2).order_by(Education.id).all()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "lo-W8V2MxKNi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from snorkel.annotations import load_gold_labels\n",
        "\n",
        "L_gold_dev  = load_gold_labels(session, annotator_name='gold', split=1)\n",
        "L_gold_test = load_gold_labels(session, annotator_name='gold', split=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yveB5sRxKNu",
        "colab_type": "text"
      },
      "source": [
        "Try tuning the hyper-parameters below to get your best F1 score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "zC9VTkRwxKN4",
        "colab_type": "code",
        "colab": {},
        "outputId": "7fc220d1-ec7f-460f-c2ba-4fe898eee0f1"
      },
      "source": [
        "# ** STUDENT CODE\n",
        "\n",
        "# TODO: tune your hyper-parameters for best results\n",
        "from snorkel.learning.pytorch import LSTM\n",
        "\n",
        "train_kwargs = {\n",
        "    'lr':            0.01, # learning rate of the model\n",
        "    'embedding_dim': 100,   # size of the feature vector\n",
        "    'hidden_dim':    100,   # number of nodes in each layer in the model\n",
        "    'n_epochs':      50,   # number of training epochs\n",
        "    'dropout':       0.2,  # dropout rate (during learning)\n",
        "    'batch_size':    64,   # training batch size\n",
        "    'seed':          1701\n",
        "}\n",
        "\n",
        "lstm = LSTM(n_threads=None)\n",
        "lstm.train(train_cands, train_marginals, X_dev=dev_cands, Y_dev=L_gold_dev, **train_kwargs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[LSTM] Training model\n",
            "[LSTM] n_train=2074  #epochs=50  batch size=64\n",
            "[LSTM] Epoch 1 (8.57s)\tAverage loss=0.296077\tDev F1=10.53\n",
            "[LSTM] Epoch 2 (17.64s)\tAverage loss=0.195196\tDev F1=58.33\n",
            "[LSTM] Epoch 3 (26.74s)\tAverage loss=0.159777\tDev F1=60.71\n",
            "[LSTM] Epoch 4 (35.86s)\tAverage loss=0.160931\tDev F1=57.78\n",
            "[LSTM] Epoch 5 (45.13s)\tAverage loss=0.147903\tDev F1=65.22\n",
            "[LSTM] Epoch 6 (53.52s)\tAverage loss=0.147180\tDev F1=65.22\n",
            "[LSTM] Epoch 7 (61.97s)\tAverage loss=0.146500\tDev F1=65.22\n",
            "[LSTM] Epoch 8 (70.72s)\tAverage loss=0.146783\tDev F1=65.12\n",
            "[LSTM] Epoch 9 (79.38s)\tAverage loss=0.145805\tDev F1=65.22\n",
            "[LSTM] Epoch 10 (87.43s)\tAverage loss=0.145532\tDev F1=65.22\n",
            "[LSTM] Epoch 11 (95.30s)\tAverage loss=0.145405\tDev F1=65.22\n",
            "[LSTM] Epoch 12 (103.78s)\tAverage loss=0.145259\tDev F1=65.22\n",
            "[LSTM] Epoch 13 (112.09s)\tAverage loss=0.145350\tDev F1=68.18\n",
            "[LSTM] Epoch 14 (121.58s)\tAverage loss=0.145248\tDev F1=68.18\n",
            "[LSTM] Epoch 15 (131.94s)\tAverage loss=0.145177\tDev F1=68.18\n",
            "[LSTM] Epoch 16 (141.37s)\tAverage loss=0.145170\tDev F1=65.22\n",
            "[LSTM] Epoch 17 (150.53s)\tAverage loss=0.145238\tDev F1=65.22\n",
            "[LSTM] Epoch 18 (159.96s)\tAverage loss=0.145231\tDev F1=65.22\n",
            "[LSTM] Epoch 19 (168.88s)\tAverage loss=0.145115\tDev F1=65.22\n",
            "[LSTM] Epoch 20 (177.60s)\tAverage loss=0.145121\tDev F1=65.22\n",
            "[LSTM] Epoch 21 (186.93s)\tAverage loss=0.145128\tDev F1=65.22\n",
            "[LSTM] Epoch 22 (195.82s)\tAverage loss=0.145049\tDev F1=65.22\n",
            "[LSTM] Epoch 23 (204.49s)\tAverage loss=0.144946\tDev F1=65.22\n",
            "[LSTM] Epoch 24 (213.03s)\tAverage loss=0.145075\tDev F1=65.22\n",
            "[LSTM] Epoch 25 (221.63s)\tAverage loss=0.145002\tDev F1=65.22\n",
            "[LSTM] Epoch 26 (231.06s)\tAverage loss=0.145016\tDev F1=65.22\n",
            "[LSTM] Epoch 27 (239.67s)\tAverage loss=0.145025\tDev F1=65.22\n",
            "[LSTM] Epoch 28 (250.17s)\tAverage loss=0.144991\tDev F1=65.22\n",
            "[LSTM] Epoch 29 (260.89s)\tAverage loss=0.144986\tDev F1=65.22\n",
            "[LSTM] Epoch 30 (270.37s)\tAverage loss=0.145027\tDev F1=65.22\n",
            "[LSTM] Epoch 31 (278.40s)\tAverage loss=0.144962\tDev F1=65.22\n",
            "[LSTM] Epoch 32 (287.12s)\tAverage loss=0.144982\tDev F1=68.18\n",
            "[LSTM] Epoch 33 (296.00s)\tAverage loss=0.144948\tDev F1=65.22\n",
            "[LSTM] Epoch 34 (304.81s)\tAverage loss=0.145001\tDev F1=65.22\n",
            "[LSTM] Epoch 35 (315.72s)\tAverage loss=0.144994\tDev F1=65.22\n",
            "[LSTM] Epoch 36 (325.23s)\tAverage loss=0.144882\tDev F1=65.22\n",
            "[LSTM] Epoch 37 (334.67s)\tAverage loss=0.144836\tDev F1=65.22\n",
            "[LSTM] Epoch 38 (343.37s)\tAverage loss=0.144940\tDev F1=65.22\n",
            "[LSTM] Epoch 39 (351.96s)\tAverage loss=0.144829\tDev F1=65.22\n",
            "[LSTM] Model saved as <LSTM>\n",
            "[LSTM] Epoch 40 (360.04s)\tAverage loss=0.144830\tDev F1=65.22\n",
            "[LSTM] Epoch 41 (368.46s)\tAverage loss=0.144995\tDev F1=65.22\n",
            "[LSTM] Epoch 42 (377.09s)\tAverage loss=0.144813\tDev F1=65.22\n",
            "[LSTM] Epoch 43 (385.41s)\tAverage loss=0.144819\tDev F1=65.22\n",
            "[LSTM] Epoch 44 (394.35s)\tAverage loss=0.144857\tDev F1=65.22\n",
            "[LSTM] Epoch 45 (404.28s)\tAverage loss=0.144870\tDev F1=65.22\n",
            "[LSTM] Epoch 46 (414.15s)\tAverage loss=0.144815\tDev F1=65.22\n",
            "[LSTM] Epoch 47 (423.74s)\tAverage loss=0.144815\tDev F1=65.22\n",
            "[LSTM] Epoch 48 (432.90s)\tAverage loss=0.144735\tDev F1=65.22\n",
            "[LSTM] Epoch 49 (442.34s)\tAverage loss=0.144801\tDev F1=65.22\n",
            "[LSTM] Epoch 50 (450.50s)\tAverage loss=0.144802\tDev F1=65.22\n",
            "[LSTM] Training done (450.84s)\n",
            "[LSTM] Loaded model <LSTM>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGSCU0gUxKOE",
        "colab_type": "text"
      },
      "source": [
        "**Report performance of your final extractor**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "KRUoyayfxKOK",
        "colab_type": "code",
        "colab": {},
        "outputId": "ee955460-c497-4b6a-b078-c38bef9532f6"
      },
      "source": [
        "p, r, f1 = lstm.score(test_cands, L_gold_test)\n",
        "print(\"Prec: {0:.3f}, Recall: {1:.3f}, F1 Score: {2:.3f}\".format(p, r, f1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prec: 0.605, Recall: 0.657, F1 Score: 0.630\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "JzWFJXF1xKOU",
        "colab_type": "code",
        "colab": {},
        "outputId": "98cc13e8-3580-4d00-b50c-dd3b81fd2ba2"
      },
      "source": [
        "tp, fp, tn, fn = lstm.error_analysis(session, test_cands, L_gold_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "========================================\n",
            "Scores (Un-adjusted)\n",
            "========================================\n",
            "Pos. class accuracy: 0.657\n",
            "Neg. class accuracy: 0.97\n",
            "Precision            0.605\n",
            "Recall               0.657\n",
            "F1                   0.63\n",
            "----------------------------------------\n",
            "TP: 23 | FP: 15 | TN: 487 | FN: 12\n",
            "========================================\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3D0uKSDxKOb",
        "colab_type": "text"
      },
      "source": [
        "Use your new model to extract relation in testing documents, and save it to JSON files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "7max-uqwxKOf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ** STUDENT CODE\n",
        "# TODO: change to your name\n",
        "save_predicted_relations(\"Rijul_Vohra_hw05_extracted_relation.test.json\", test_cands, lstm.predictions(test_cands))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ED83eesSxKOr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}